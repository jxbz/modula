Search.setIndex({"docnames": ["bad-scaling", "golden-rules", "history", "index", "theory/atom/conv2d", "theory/atom/embed", "theory/atom/index", "theory/atom/linear", "theory/bond/index", "theory/bond/nonlinearities", "theory/compound/gpt", "theory/compound/index", "theory/module", "theory/vector"], "filenames": ["bad-scaling.rst", "golden-rules.rst", "history.rst", "index.rst", "theory/atom/conv2d.rst", "theory/atom/embed.rst", "theory/atom/index.rst", "theory/atom/linear.rst", "theory/bond/index.rst", "theory/bond/nonlinearities.rst", "theory/compound/gpt.rst", "theory/compound/index.rst", "theory/module.rst", "theory/vector.rst"], "titles": ["Bad scaling", "Golden rules for scaling", "The science of scale", "Welcome to the Modula docs!", "Conv2d", "Embedding", "Atomic modules", "Linear", "Bond modules", "Nonlinearities", "GPT", "Compound modules", "Modules", "Vectors"], "terms": {"At": [0, 1], "simplest": 0, "level": 0, "neural": [0, 1, 2, 3], "network": [0, 1, 2, 3], "ar": [0, 1], "train": [0, 1, 3], "iter": [0, 1], "follow": [0, 1], "oper": [0, 1], "weight": [0, 1], "learning_r": [0, 1], "gradient": [0, 1, 2], "where": [0, 1], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "float": [0, 1], "loss": [0, 1], "function": [0, 1], "respect": [0, 1], "Of": 0, "cours": [0, 1], "practic": [0, 1], "we": [0, 1], "mai": [0, 1], "want": [0, 1, 3], "us": [0, 1, 2, 3], "addit": 0, "trick": 0, "momentum": [0, 1], "let": [0, 1], "": [0, 1], "ignor": 0, "detail": 0, "like": [0, 2, 3], "now": [0, 1], "unfortun": 0, "thi": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "simpl": [0, 1], "descent": [0, 1, 2], "doe": [0, 1], "well": 0, "up": 0, "architectur": [0, 1], "what": [0, 1], "mean": [0, 1], "suppos": 0, "befor": 0, "grow": 0, "increas": [0, 1], "its": [0, 1], "width": [0, 2], "number": [0, 1], "neuron": 0, "layer": 0, "depth": 0, "In": [0, 1], "might": [0, 1, 3], "other": [0, 1, 2], "dimens": [0, 1], "residu": [0, 1], "block": [0, 1], "transform": [0, 1], "stick": 0, "simplifi": 0, "pictur": 0, "under": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "can": [0, 1, 3], "break": 0, "two": [0, 2], "main": [0, 1], "wai": [0, 1], "The": [0, 3], "first": [0, 1], "problem": [0, 1], "optim": [0, 2, 3], "learn": [0, 1, 2, 3], "rate": [0, 1, 3], "drift": 0, "certain": 0, "becaus": [0, 1, 2], "need": [0, 1], "re": 0, "tune": 0, "thing": 0, "which": [0, 1], "expens": 0, "time": 0, "consum": 0, "second": [0, 1], "sometim": 0, "perform": [0, 1], "actual": 0, "get": [0, 1], "wors": [0, 1], "even": [0, 1, 2], "remain": 0, "stabl": 0, "grew": 0, "hope": [0, 1], "make": [0, 1, 2], "better": [0, 3], "These": 0, "cartoon": 0, "illustr": [0, 1], "typic": 0, "behaviour": 0, "On": [0, 1, 2], "left": 0, "right": [0, 1], "deterior": 0, "good": [0, 1], "new": [0, 1], "have": [0, 1], "develop": 0, "machineri": 0, "larg": [0, 1, 2, 3], "solv": 0, "woe": 0, "It": [0, 1], "turn": [0, 1, 2], "out": [0, 1, 2], "defin": 0, "initi": [0, 1], "along": 0, "special": 0, "normal": [0, 1], "act": 0, "lead": 0, "algorithm": 0, "remov": 0, "caus": [0, 1], "improv": 0, "modula": [0, 1], "automat": [0, 2, 3], "infer": 0, "necessari": 0, "from": [0, 1], "so": [0, 1, 2], "user": 0, "focu": 0, "write": 0, "while": [0, 1], "handl": 0, "properli": 0, "doc": 0, "intend": 0, "explain": [0, 1, 3], "how": [0, 1, 3], "work": [0, 1, 2], "also": [0, 1], "introduc": [0, 1, 3], "api": [0, 3], "case": [0, 1], "you": [0, 1, 2, 3], "don": [0, 1, 3], "t": [0, 1, 3], "care": [0, 3], "about": [0, 1, 3], "next": [0, 1], "section": [0, 1, 3], "manual": 0, "differ": [0, 1], "framework": [0, 1, 3], "pytorch": [0, 3], "jax": [0, 3], "your": 1, "huh": [1, 2, 3], "too": 1, "difficult": 1, "boil": 1, "down": 1, "few": 1, "principl": 1, "some": [1, 2], "basic": 1, "algebra": 1, "bad": 1, "requir": 1, "unlearn": 1, "concept": 1, "been": 1, "taught": 1, "lectur": 1, "For": 1, "exampl": 1, "consid": 1, "all": 1, "activ": 1, "unit": 1, "varianc": 1, "deep": [1, 2, 3], "101": 1, "why": 1, "intern": 1, "behav": 1, "quit": 1, "compar": 1, "after": 1, "step": 1, "A": [1, 2], "understand": 1, "point": 1, "gaussian": 1, "standard": 1, "deviat": 1, "sigma": 1, "class": 1, "def": 1, "__init__": 1, "self": 1, "fan_out": 1, "int": 1, "fan_in": 1, "torch": 1, "randn": 1, "forward": 1, "x": 1, "return": 1, "matmul": 1, "properti": 1, "most": 1, "subtl": 1, "when": 1, "conduct": 1, "reduct": 1, "e": 1, "much": 1, "smaller": 1, "than": [1, 3], "happen": 1, "final": 1, "classifi": 1, "fact": 1, "studi": 1, "hold": 1, "an": 1, "import": 1, "matrix": 1, "larger": 1, "null": 1, "space": 1, "huge": 1, "input": 1, "map": 1, "zero": 1, "least": 1, "lie": 1, "nullspac": 1, "output": 1, "pick": 1, "order": 1, "compon": 1, "But": 1, "situat": 1, "chang": 1, "align": 1, "non": 1, "chose": 1, "control": 1, "far": 1, "hindsight": 1, "blow": 1, "onli": 1, "solut": 1, "choos": 1, "instead": 1, "assumpt": 1, "fall": 1, "small": 1, "fine": 1, "thei": 1, "quickli": 1, "warm": 1, "And": 1, "nice": 1, "bonu": 1, "show": 1, "switch": 1, "init": 1, "orthogon": 1, "trivial": 1, "previou": 1, "style": 1, "think": [1, 2], "extend": [1, 3], "beyond": 1, "distil": 1, "tenet": 1, "call": 1, "largest": 1, "spectral": [1, 2], "tensor": 1, "carefulli": 1, "set": 1, "updat": 1, "size": 1, "dure": 1, "keep": 1, "mind": 1, "design": [1, 3], "worth": 1, "expand": 1, "littl": 1, "here": [1, 2], "sai": 1, "comput": 1, "u": [1, 2], "v": 1, "linalg": 1, "svd": 1, "tend": 1, "row": 1, "correspond": 1, "diagon": 1, "entri": 1, "singular": 1, "valu": 1, "one": 1, "sourc": 1, "middl": 1, "net": 1, "preced": 1, "head": 1, "tail": 1, "know": 1, "both": 1, "through": [1, 3], "backpropag": 1, "appli": 1, "1": 1, "kind": 1, "everi": 1, "rest": 1, "do": 1, "should": 1, "alreadi": 1, "enough": 1, "start": 1, "gpt": 1, "ha": 1, "reach": [1, 2], "fulli": 1, "state": 1, "roughli": 1, "interv": 1, "equival": 1, "euclidean": 1, "length": 1, "math": [1, 3], "sqrt": 1, "To": 1, "achiev": 1, "tell": 1, "top": 1, "One": 1, "check": 1, "proport": 1, "intuit": 1, "factor": 1, "dimension": 1, "convert": 1, "take": 1, "vector": 1, "spit": 1, "more": [1, 2], "clever": 1, "reparameter": 1, "reparameterizedlinear": 1, "empti": 1, "nn": 1, "orthogonal_": 1, "By": 1, "includ": 1, "convers": 1, "correct": 1, "easi": 1, "just": [1, 3], "exactli": 1, "our": [1, 3], "experi": 1, "found": 1, "hyperparamet": [1, 2], "free": [1, 2], "As": 1, "them": 1, "2": 1, "grad": 1, "spectral_norm": 1, "replac": 1, "adam": 1, "express": 1, "option": 1, "decai": 1, "look": 1, "3": 1, "form": 1, "resnet": 1, "residue_list": 1, "list": 1, "block_multipli": 1, "each": 1, "loop": 1, "ad": 1, "sub": 1, "ensur": 1, "contribut": 1, "allow": 1, "veri": 1, "without": [1, 2], "question": 1, "third": 1, "answer": 1, "len": 1, "add": 1, "total": 1, "sum": 1, "divid": 1, "similar": 1, "idea": 1, "seen": 1, "frac": 1, "l": 1, "mathrm": 1, "ani": 1, "0": 1, "though": 1, "involv": 1, "term": 1, "prevent": 1, "link": 1, "analogi": 1, "back": 1, "plai": 1, "role": 1, "sinc": 1, "multipli": 1, "safe": 1, "equal": 1, "long": 1, "individu": 1, "accord": 1, "4": 1, "between": [1, 2], "convention": 1, "done": 1, "lambda": 1, "shape": 1, "assum": 1, "uncorrel": 1, "random": 1, "expect": 1, "becom": 1, "therefor": 1, "spell": 1, "clearli": 1, "quantiti": 1, "page": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "convent": 1, "wisdom": 1, "someth": 1, "across": [1, 3], "logic": 1, "associ": 1, "scalabl": [1, 2, 3], "approach": 1, "base": 1, "simpler": 1, "anyth": 1, "variabl": 1, "object": 1, "same": 1, "direct": 1, "vein": 1, "obviat": 1, "matric": 1, "histori": 1, "behind": 1, "move": 1, "autom": 1, "applic": 1, "mathemat": 1, "analogu": 1, "statement": 1, "outer": 1, "norm": [1, 2, 3], "alwai": 1, "over": 1, "mlp": 1, "seem": 1, "10": 1, "paper": 1, "type": 1, "propos": 1, "smooth": 1, "limit": 1, "infinit": [1, 2], "mani": 1, "best": 1, "knowledg": 1, "recurs": 1, "natur": 1, "directli": [1, 3], "inspir": 1, "still": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "construct": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "wa": 2, "written": [2, 3], "jeremi": [2, 3], "bias": 2, "hi": 2, "view": 2, "world": 2, "he": 2, "put": 2, "provid": 2, "counterpoint": 2, "prevail": 2, "narr": 2, "If": [2, 3], "d": 2, "mention": 2, "feel": 2, "either": 2, "pull": 2, "request": 2, "email": 2, "twist": 2, "distanc": 2, "stabil": 2, "bernstein": [2, 3], "arash": 2, "vahdat": 2, "yisong": 2, "yue": 2, "ming": 2, "yu": 2, "liu": [2, 3], "neurip": 2, "2020": 2, "text": 2, "featur": 2, "greg": 2, "yang": [2, 3], "edward": 2, "j": 2, "hu": 2, "icml": 2, "2021": 2, "condit": 2, "jame": 2, "b": 2, "simon": 2, "arxiv": [2, 3], "2023": 2, "chri": 2, "mingard": 2, "kevin": 2, "huang": 2, "navid": 2, "azizan": 2, "modular": [2, 3], "tim": [2, 3], "minyoung": [2, 3], "hyojin": [2, 3], "bahng": [2, 3], "phillip": [2, 3], "isola": [2, 3], "2024": [2, 3], "grace": 3, "scale": 3, "transfer": 3, "instal": 3, "run": 3, "pip": 3, "three": 3, "fold": 3, "teach": 3, "code": 3, "skip": 3, "golden": 3, "rule": 3, "otherwis": 3, "side": 3, "panel": 3, "arrow": 3, "kei": 3, "jump": 3, "around": 3, "prefer": 3, "read": 3, "articl": 3, "author": 3, "titl": 3, "journal": 3, "2405": 3, "14813": 3, "year": 3}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"bad": 0, "scale": [0, 1, 2], "golden": 1, "rule": 1, "The": [1, 2], "linear": [1, 7], "layer": 1, "three": 1, "fix": 1, "width": 1, "depth": 1, "kei": 1, "queri": 1, "dot": 1, "product": 1, "wrap": 1, "up": 1, "scienc": 2, "warn": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "pre": 2, "histori": 2, "truth": 2, "reconcili": 2, "autom": 2, "train": 2, "welcom": 3, "modula": 3, "doc": 3, "purpos": 3, "navig": 3, "companion": 3, "paper": 3, "conv2d": 4, "embed": 5, "atom": 6, "modul": [6, 8, 11, 12], "bond": 8, "nonlinear": 9, "gpt": 10, "compound": 11, "vector": 13}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Bad scaling": [[0, "bad-scaling"]], "Golden rules for scaling": [[1, "golden-rules-for-scaling"]], "The linear layer": [[1, "the-linear-layer"]], "Three golden rules": [[1, "three-golden-rules"]], "Fixing width scaling": [[1, "fixing-width-scaling"]], "Fixing depth scaling": [[1, "fixing-depth-scaling"]], "Fixing key-query dot product scaling": [[1, "fixing-key-query-dot-product-scaling"]], "Wrapping up": [[1, "wrapping-up"]], "The science of scale": [[2, "the-science-of-scale"]], "Warning": [[2, null], [2, null], [4, null], [5, null], [6, null], [7, null], [8, null], [9, null], [10, null], [11, null], [12, null], [13, null]], "Pre-history": [[2, "pre-history"]], "Truth and reconciliation": [[2, "truth-and-reconciliation"]], "Automation of training": [[2, "automation-of-training"]], "Welcome to the Modula docs!": [[3, "welcome-to-the-modula-docs"]], "Purpose of the docs": [[3, "purpose-of-the-docs"]], "Navigating the docs": [[3, "navigating-the-docs"]], "Companion paper": [[3, "companion-paper"]], "Conv2d": [[4, "conv2d"]], "Embedding": [[5, "embedding"]], "Atomic modules": [[6, "atomic-modules"]], "Linear": [[7, "linear"]], "Bond modules": [[8, "bond-modules"]], "Nonlinearities": [[9, "nonlinearities"]], "GPT": [[10, "gpt"]], "Compound modules": [[11, "compound-modules"]], "Modules": [[12, "modules"]], "Vectors": [[13, "vectors"]]}, "indexentries": {}})